\ifdefined\included
\else
\documentclass[english, a4paper,11pt,twoside]{StyleThese}
\include{formatAndDefs}
\sloppy
\begin{document}
\fi


\chapter*{Conclusion}
\addstarredchapter{Conclusion} %Sinon cela n'apparait pas dans la table des mati√®res

\section*{Contributions}
\addcontentsline{toc}{section}{Contributions}

This manuscript presented several contributions to the field of human-robot cooperative task achievement. These contributions have been grouped in three parts:
\begin{itemize}
\item In a first part, we studied the basis of the Joint Action principles in order to build a supervisor for human-robot Joint Action. 
\begin{itemize}
\item In Chapter~\ref{ch:biblio}, we first studied the bibliography about Joint Action between humans in social science in order to identify what are the needed components for a robot decision adapted to Joint Action. Secondly, we looked how these components have already been applied in robotics and, finally, we studied how to articulate all these components and how, inspired by models from philosophy, we can build a robotics architecture for human-robot Joint Action.
\item In Chapter~\ref{ch:Sup}, we presented the supervisor for human-robot collaboration which has been developed and improved during the thesis. This supervisor is the main technical contribution of the thesis.
\end{itemize}
\item In a second part, we focused on the achievement by a robot of a \textit{Shared Plan} in collaboration with a human:
\begin{itemize}
\item In Chapter~\ref{ch:MS}, we presented how we endowed the robot with the ability to estimate the humans mental states, not only about the environment, but also concerning the state of the task and more particularly of the Shared Plan. We have also shown how we used these mental states to allow the robot to better communicate about divergent beliefs during Shared Plan execution.
\item In Chapter~\ref{ch:SP}, we described the work done in order to allow the robot to gain acceptability and fluency during Shared Plan achievement by working with more flexible Shared Plans. We first identified the needed decisions during Shared Plan elaboration and execution and we endowed the robot with the ability to decide which decisions should be taken at planning time and which ones are better postponed to execution time. Then, we allowed the robot to take these decision by smoothly adapting to the human choices.
\item Finally, in Chapter~\ref{ch:Eval}, we evaluated the new implemented system for the achievement of human-robot Shared Plan. This evaluation has been done quantitatively in simulation but also qualitatively with a user study with the real robot. Both evaluations highlighted the pertinence of the improvements brought to the system. A questionnaire allowing to evaluate the users feelings about a collaboration with a robot has been developed and validated (in terms of intern coherence) in the context of the user study. Moreover, this user study allows us to get more insights on experiments with naive subjects.
\end{itemize} 
In the last part, we presented other contributions to the domain:
\begin{itemize}
\item In Chapter~\ref{ch:Acting}, we studied the non-verbal behavior, and more especially the head -gaze- behavior, needed during Joint Action between humans and between a human and a robot. We identified the needed components of a robot head behavior adapted to the Joint Action and investigated more deeply some of them with an on-line video based study. Finally, we presented how these components can be implemented into a robot head behavior architecture.
\item In Chapter~\ref{ch:Learning}, inspired from studies in neuroscience, we combined learning and planning for high level decisions during human-robot Joint Action. The idea being to take advantage from both techniques in order to come up with decision level which is able to quickly learn how to smoothly adapt to the human choices during Joint Action execution.
\end{itemize}
\end{itemize}

\section*{Future works and improvements}
\addcontentsline{toc}{section}{Future works and improvements}

All these contributions made a step toward the aim of a full autonomous robot able to work jointly with humans in the context of Joint Action. However there is still plenty room for improvements and plenty other enhancements to bring to attain this goal. Concerning the work presented in this manuscript:
\begin{itemize}
\item Concerning the work on Shared Plan achievement, there is still plenty of possible modifications in order for the execution to be even more flexible and adapted to the human choices. We can mention, among others, the possibility to deal with the temporary absence of the human by computing plans where the robot tries to achieve the maximum on its own for a time while keeping in mind that the human should return in order to achieve the action only him can perform (instead of failing because nobody can achieve these actions anymore).
\item Concerning the work on the robot head behavior, the next step is to implement the proposed architecture on the robot. Once this done, it will be interesting to evaluate this architecture through a user study. It will also be interesting to make the link between the signals transmitted and the estimated mental states of the humans. Indeed, when the robot transmits a signal, in addition to make sure that the signal has been well received, it should update the mental state of its partner with the information that he received the signal and all what it implies. Finally, this work should be extended to the rest of the robot non-verbal behavior.
\item Concerning the work on the combination of learning and planning, there is still work to do to have a conclusive architecture for high level decisions. Moreover, it can be interesting to improve the combination by allowing the planner to learn costs and execution times and maybe probabilities of success as well from the learning in order to update its model and come up with more appropriate plans.
\end{itemize}
We can also mention, among others, several other improvements to bring to the current system:
\begin{itemize}
\item it could be interesting focus on issues relative to engagement during human-robot Joint Action. The robot should be able, in addition to detect to the engagement of its human partners on the current task, to deal with small distraction of its partner (without thinking the partner is disengaged from the goal) or interruptions of the task to perform by another one (imagine you give a long task to perform to your robot in collaboration with your son, you want to be able to interrupt it the time it brings you a beer).
\item It can also be interesting to link humans actions perception to the Shared Plan execution. Indeed, knowing what are the possible actions of the human and what are the actions we expect him to do can help the robot to have a more robust detection of humans actions.
\item Finally, it could also be interesting to work on the link between dialogue and supervision during Joint Action. There are two possibilities, and in my point of view needed approaches to do it. First the dialogue can be seen as a tool to the Joint Action execution (e.g. as started in this thesis by giving appropriate information at the right time). Secondly, the dialogue can also be seen as a full Joint Action, with the supervision helping to perform actions supporting the dialogue (e.g. pointing a point of interest). Moreover, a strong coordination should be done between the non-verbal behavior needed during dialogue and the one needed during Shared Plan execution.
\end{itemize}

\ifdefined\included
\else
\bibliographystyle{StyleThese}
\bibliography{These}
\end{document}
\fi